"""
TextVectorizerã®åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆ

ä»¥ä¸‹ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™:
- åŸºæœ¬çš„ãªãƒ™ã‚¯ãƒˆãƒ«åŒ–
- ãƒãƒƒãƒå‡¦ç†
- ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦è¨ˆç®—
- é¡ä¼¼åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹
- ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢
- æ¬¡å…ƒå‰Šæ¸›ï¼ˆPCA, UMAPï¼‰
- DataFrameå¤‰æ›
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹é‡è¦ãªæ³¨æ„äº‹é …:
- ã“ã®TextVectorizerã¯ã™ã¹ã¦ã®å‡¦ç†ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ï¼ˆã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹ï¼‰ã§å®Ÿè¡Œã—ã¾ã™
- Sentence-Transformersãƒ¢ãƒ‡ãƒ«ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ä¿å­˜ã•ã‚Œã¾ã™
- æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã¯ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã«é€ä¿¡ã•ã‚Œã¾ã›ã‚“
- ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¡ãƒ¢ãƒªã®ã¿ã«ä¿æŒã•ã‚Œã¾ã™
- å¤–éƒ¨APIå‘¼ã³å‡ºã—ã¯è¡Œã‚ã‚Œã¾ã›ã‚“
"""

import unittest
import numpy as np
import pandas as pd
import sys
import time
from pathlib import Path

# ãƒ‘ã‚¹ã‚’è¿½åŠ ã—ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.insert(0, str(Path(__file__).parent.parent / 'ai-chat-analyzer' / 'src'))

from analysis.vectorizer import TextVectorizer


class TestTextVectorizerBasic(unittest.TestCase):
    """åŸºæœ¬çš„ãªãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ†ã‚¹ãƒˆ"""
    
    @classmethod
    def setUpClass(cls):
        """å…¨ãƒ†ã‚¹ãƒˆã§å…±é€šã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        print("\n[INFO] TextVectorizerã‚’åˆæœŸåŒ–ä¸­ï¼ˆåˆå›å®Ÿè¡Œæ™‚ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰...")
        cls.vectorizer = TextVectorizer()
    
    def test_encode_single_text(self):
        """å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
        text = "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆã§ã™"
        embedding = self.vectorizer.encode(text)
        
        # ãƒ™ã‚¯ãƒˆãƒ«ã®å½¢çŠ¶ã‚’ç¢ºèª
        self.assertEqual(len(embedding.shape), 2)
        self.assertEqual(embedding.shape[0], 1)  # 1ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆ
        self.assertGreater(embedding.shape[1], 0)  # æ¬¡å…ƒ > 0
        
        # ãƒ™ã‚¯ãƒˆãƒ«ã®å€¤ãŒæ­£è¦åŒ–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆL2ãƒãƒ«ãƒ  â‰ˆ 1ï¼‰
        norm = np.linalg.norm(embedding[0])
        self.assertAlmostEqual(norm, 1.0, places=5)
        
        print("[PASS] å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ†ã‚¹ãƒˆ")
    
    def test_encode_multiple_texts(self):
        """è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
        texts = [
            "ã“ã‚Œã¯ãƒ†ã‚­ã‚¹ãƒˆ1ã§ã™",
            "ã“ã‚Œã¯ãƒ†ã‚­ã‚¹ãƒˆ2ã§ã™",
            "ã“ã‚Œã¯ãƒ†ã‚­ã‚¹ãƒˆ3ã§ã™"
        ]
        embeddings = self.vectorizer.encode(texts)
        
        # ãƒ™ã‚¯ãƒˆãƒ«ã®å½¢çŠ¶ã‚’ç¢ºèª
        self.assertEqual(embeddings.shape[0], 3)
        self.assertGreater(embeddings.shape[1], 0)
        
        # å„ãƒ™ã‚¯ãƒˆãƒ«ãŒæ­£è¦åŒ–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        for i in range(3):
            norm = np.linalg.norm(embeddings[i])
            self.assertAlmostEqual(norm, 1.0, places=5)
        
        print("[PASS] è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ†ã‚¹ãƒˆ")
    
    def test_encode_japanese_text(self):
        """æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
        texts = [
            "ã“ã‚“ã«ã¡ã¯",
            "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™",
            "ã“ã‚“ã°ã‚“ã¯"
        ]
        embeddings = self.vectorizer.encode(texts)
        
        self.assertEqual(embeddings.shape[0], 3)
        self.assertGreater(embeddings.shape[1], 0)
        
        print("[PASS] æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ†ã‚¹ãƒˆ")
    
    def test_encode_mixed_language(self):
        """æ··åˆè¨€èªãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
        texts = [
            "Hello world",
            "ã“ã‚“ã«ã¡ã¯",
            "ä½ å¥½"
        ]
        embeddings = self.vectorizer.encode(texts)
        
        self.assertEqual(embeddings.shape[0], 3)
        
        print("[PASS] æ··åˆè¨€èªãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ†ã‚¹ãƒˆ")
    
    def test_encode_special_characters(self):
        """ç‰¹æ®Šæ–‡å­—ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
        texts = [
            "Email: test@example.com",
            "URL: https://example.com",
            "çµµæ–‡å­—: ğŸ˜Š ğŸ‘ ğŸ‰",
            "æ•°å­—: 123, 456, 789"
        ]
        embeddings = self.vectorizer.encode(texts)
        
        self.assertEqual(embeddings.shape[0], 4)
        
        print("[PASS] ç‰¹æ®Šæ–‡å­—ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ†ã‚¹ãƒˆ")
    
    def test_embed_consistency(self):
        """åŒã˜ãƒ†ã‚­ã‚¹ãƒˆã®åŒã˜ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
        text = "ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ"
        embedding1 = self.vectorizer.encode(text)
        embedding2 = self.vectorizer.encode(text)
        
        # åŒã˜ãƒ†ã‚­ã‚¹ãƒˆã¯åŒã˜ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¿”ã™
        np.testing.assert_array_almost_equal(embedding1, embedding2, decimal=5)
        
        print("[PASS] ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã®ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ")


class TestTextVectorizerSimilarity(unittest.TestCase):
    """ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦è¨ˆç®—ã®ãƒ†ã‚¹ãƒˆ"""
    
    @classmethod
    def setUpClass(cls):
        cls.vectorizer = TextVectorizer()
    
    def test_similarity_identical_texts(self):
        """åŒä¸€ãƒ†ã‚­ã‚¹ãƒˆã®é¡ä¼¼åº¦"""
        text = "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆã§ã™"
        similarity = self.vectorizer.similarity(text, text)
        
        # åŒä¸€ãƒ†ã‚­ã‚¹ãƒˆã¯å®Œå…¨ã«é¡ä¼¼
        self.assertAlmostEqual(similarity, 1.0, places=3)
        
        print("[PASS] åŒä¸€ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦ãƒ†ã‚¹ãƒˆ")
    
    def test_similarity_different_texts(self):
        """ç•°ãªã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®é¡ä¼¼åº¦"""
        text1 = "çŠ¬"
        text2 = "çŒ«"
        similarity = self.vectorizer.similarity(text1, text2)
        
        # ç•°ãªã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯0ï½1ã®é–“
        self.assertGreaterEqual(similarity, -1.0)
        self.assertLessEqual(similarity, 1.0)
        
        print("[PASS] ç•°ãªã‚‹ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦ãƒ†ã‚¹ãƒˆ")
    
    def test_similarity_related_texts(self):
        """é–¢é€£ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã®é¡ä¼¼åº¦"""
        text1 = "ç§ã¯çŒ«ãŒå¥½ãã§ã™"
        text2 = "çŒ«ã¯ç§ã®å¥½ããªå‹•ç‰©ã§ã™"
        similarity = self.vectorizer.similarity(text1, text2)
        
        # é–¢é€£ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã¯é«˜ã„é¡ä¼¼åº¦
        self.assertGreater(similarity, 0.5)
        
        print("[PASS] é–¢é€£ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦ãƒ†ã‚¹ãƒˆ")
    
    def test_similarity_matrix(self):
        """é¡ä¼¼åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¨ˆç®—"""
        texts = [
            "çŠ¬ã¯å‹•ç‰©ã§ã™",
            "çŒ«ã¯å‹•ç‰©ã§ã™",
            "ã‚Šã‚“ã”ã¯æœç‰©ã§ã™"
        ]
        similarity_matrix = self.vectorizer.similarity_matrix(texts)
        
        # ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã®å½¢çŠ¶
        self.assertEqual(similarity_matrix.shape, (3, 3))
        
        # å¯¾è§’ç·šã¯1ï¼ˆè‡ªåˆ†è‡ªèº«ï¼‰
        for i in range(3):
            self.assertAlmostEqual(similarity_matrix[i, i], 1.0, places=3)
        
        # å¯¾ç§°è¡Œåˆ—
        for i in range(3):
            for j in range(3):
                self.assertAlmostEqual(similarity_matrix[i, j], 
                                     similarity_matrix[j, i], places=5)
        
        print("[PASS] é¡ä¼¼åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆ")


class TestTextVectorizerSearch(unittest.TestCase):
    """ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ã®ãƒ†ã‚¹ãƒˆ"""
    
    @classmethod
    def setUpClass(cls):
        cls.vectorizer = TextVectorizer()
        cls.candidates = [
            "Python ã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™",
            "JavaScript ã¯ Web é–‹ç™ºã«ä½¿ç”¨ã•ã‚Œã¾ã™",
            "Ruby ã¯ç¾ã—ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™",
            "Java ã¯ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºé–‹ç™ºã«ä½¿ç”¨ã•ã‚Œã¾ã™",
            "C++ ã¯é«˜æ€§èƒ½è¨€èªã§ã™"
        ]
    
    def test_find_similar_basic(self):
        """åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢"""
        query = "Python ã‚’ä½¿ã£ãŸãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°"
        results = self.vectorizer.find_similar_texts(query, self.candidates, top_k=2)
        
        # çµæœã®å½¢å¼ã‚’ç¢ºèª
        self.assertEqual(len(results), 2)
        self.assertEqual(len(results[0]), 2)  # (text, score)
        
        # æœ€ã‚‚ä¼¼ãŸãƒ†ã‚­ã‚¹ãƒˆã¯æœ€åˆ
        self.assertGreater(results[0][1], results[1][1])
        
        print("[PASS] åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ãƒ†ã‚¹ãƒˆ")
    
    def test_find_similar_top_k(self):
        """ç•°ãªã‚‹top_kå€¤ã§ã®æ¤œç´¢"""
        query = "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª"
        
        for top_k in [1, 3, 5]:
            results = self.vectorizer.find_similar_texts(query, self.candidates, top_k=top_k)
            self.assertEqual(len(results), min(top_k, len(self.candidates)))
        
        print("[PASS] top_kå€¤ãƒ†ã‚¹ãƒˆ")
    
    def test_find_similar_ordering(self):
        """æ¤œç´¢çµæœã¯é¡ä¼¼åº¦ã®é™é †"""
        query = "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°"
        results = self.vectorizer.find_similar_texts(query, self.candidates, top_k=5)
        
        # é¡ä¼¼åº¦ãŒé™é †ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        for i in range(len(results) - 1):
            self.assertGreaterEqual(results[i][1], results[i+1][1])
        
        print("[PASS] æ¤œç´¢çµæœé †åºãƒ†ã‚¹ãƒˆ")


class TestTextVectorizerDataFrame(unittest.TestCase):
    """DataFrameå¤‰æ›ã®ãƒ†ã‚¹ãƒˆ"""
    
    @classmethod
    def setUpClass(cls):
        cls.vectorizer = TextVectorizer()
    
    def test_to_dataframe_basic(self):
        """åŸºæœ¬çš„ãªDataFrameå¤‰æ›"""
        texts = ["ãƒ†ã‚­ã‚¹ãƒˆ1", "ãƒ†ã‚­ã‚¹ãƒˆ2", "ãƒ†ã‚­ã‚¹ãƒˆ3"]
        df = self.vectorizer.to_dataframe(texts)
        
        # DataFrameã®å½¢çŠ¶
        self.assertEqual(len(df), 3)
        self.assertIn("text", df.columns)
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚«ãƒ©ãƒ ã®ç¢ºèª
        self.assertEqual(df["text"].tolist(), texts)
        
        # ãƒ™ã‚¯ãƒˆãƒ«ã‚«ãƒ©ãƒ ã®ç¢ºèª
        embedding_cols = [col for col in df.columns if col.startswith("embedding_")]
        self.assertEqual(len(embedding_cols), self.vectorizer.embedding_dim)
        
        print("[PASS] DataFrameå¤‰æ›ãƒ†ã‚¹ãƒˆ")
    
    def test_to_dataframe_with_precomputed_embeddings(self):
        """äº‹å‰è¨ˆç®—ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ã§ã®DataFrameå¤‰æ›"""
        texts = ["ãƒ†ã‚­ã‚¹ãƒˆ1", "ãƒ†ã‚­ã‚¹ãƒˆ2"]
        embeddings = self.vectorizer.encode(texts)
        
        df = self.vectorizer.to_dataframe(texts, embeddings)
        
        self.assertEqual(len(df), 2)
        self.assertIn("text", df.columns)
        
        print("[PASS] äº‹å‰è¨ˆç®—ãƒ™ã‚¯ãƒˆãƒ« DataFrameå¤‰æ›ãƒ†ã‚¹ãƒˆ")


class TestTextVectorizerDimensionReduction(unittest.TestCase):
    """æ¬¡å…ƒå‰Šæ¸›ã®ãƒ†ã‚¹ãƒˆ"""
    
    @classmethod
    def setUpClass(cls):
        cls.vectorizer = TextVectorizer()
        cls.texts = ["ãƒ†ã‚­ã‚¹ãƒˆ " + str(i) for i in range(10)]
        cls.embeddings = cls.vectorizer.encode(cls.texts)
    
    def test_reduce_dimensions_pca(self):
        """PCAã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›"""
        reduced = self.vectorizer.reduce_dimensions(
            self.embeddings,
            n_components=2,
            method="pca"
        )
        
        # å½¢çŠ¶ã®ç¢ºèª
        self.assertEqual(reduced.shape[0], len(self.embeddings))
        self.assertEqual(reduced.shape[1], 2)
        
        print("[PASS] PCAæ¬¡å…ƒå‰Šæ¸›ãƒ†ã‚¹ãƒˆ")
    
    def test_reduce_dimensions_umap(self):
        """UMAPã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›"""
        try:
            reduced = self.vectorizer.reduce_dimensions(
                self.embeddings,
                n_components=2,
                method="umap"
            )
            
            self.assertEqual(reduced.shape[0], len(self.embeddings))
            self.assertEqual(reduced.shape[1], 2)
            
            print("[PASS] UMAPæ¬¡å…ƒå‰Šæ¸›ãƒ†ã‚¹ãƒˆ")
        except ImportError:
            print("[SKIP] UMAPæ¬¡å…ƒå‰Šæ¸›ãƒ†ã‚¹ãƒˆ (umap-learn not installed)")
    
    def test_reduce_dimensions_invalid_method(self):
        """ä¸æ­£ãªæ¬¡å…ƒå‰Šæ¸›æ–¹æ³•"""
        with self.assertRaises(ValueError):
            self.vectorizer.reduce_dimensions(
                self.embeddings,
                n_components=2,
                method="invalid_method"
            )
        
        print("[PASS] ä¸æ­£ãªæ¬¡å…ƒå‰Šæ¸›æ–¹æ³•ãƒ†ã‚¹ãƒˆ")


class TestTextVectorizerModelInfo(unittest.TestCase):
    """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®ãƒ†ã‚¹ãƒˆ"""
    
    @classmethod
    def setUpClass(cls):
        cls.vectorizer = TextVectorizer()
    
    def test_get_model_info(self):
        """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®å–å¾—"""
        info = self.vectorizer.get_model_info()
        
        self.assertIn("model_name", info)
        self.assertIn("embedding_dimension", info)
        self.assertIn("device", info)
        self.assertIn("max_seq_length", info)
        
        self.assertGreater(info["embedding_dimension"], 0)
        self.assertIn(info["device"], ["cpu", "cuda"])
        
        print("[PASS] ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—ãƒ†ã‚¹ãƒˆ")
    
    def test_repr(self):
        """__repr__ãƒ¡ã‚½ãƒƒãƒ‰"""
        repr_str = repr(self.vectorizer)
        
        self.assertIn("TextVectorizer", repr_str)
        self.assertIn("embedding", repr_str.lower())
        
        print("[PASS] __repr__ãƒ†ã‚¹ãƒˆ")


class TestTextVectorizerErrorHandling(unittest.TestCase):
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""
    
    @classmethod
    def setUpClass(cls):
        cls.vectorizer = TextVectorizer()
    
    def test_encode_empty_list(self):
        """ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆ"""
        with self.assertRaises(ValueError):
            self.vectorizer.encode([])
        
        print("[PASS] ç©ºãƒªã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ")
    
    def test_encode_none_text(self):
        """Noneãƒ†ã‚­ã‚¹ãƒˆ"""
        with self.assertRaises((TypeError, ValueError)):
            self.vectorizer.encode(None)
        
        print("[PASS] Noneãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ")


class TestTextVectorizerSecurity(unittest.TestCase):
    """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆï¼ˆæ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ä¿è­·ï¼‰"""
    
    @classmethod
    def setUpClass(cls):
        cls.vectorizer = TextVectorizer()
    
    def test_local_only_processing(self):
        """ãƒ­ãƒ¼ã‚«ãƒ«ã®ã¿ã§ã®å‡¦ç†ç¢ºèª"""
        # æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã®ä¾‹
        sensitive_text = "ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰: 1234-5678-9012-3456"
        
        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†ã®ã¿ï¼‰
        embedding = self.vectorizer.encode(sensitive_text)
        
        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–æˆåŠŸ = ãƒ­ãƒ¼ã‚«ãƒ«å‡¦ç†å®Œäº†
        self.assertIsNotNone(embedding)
        self.assertTrue(np.all(np.isfinite(embedding)))
        
        print("[OK] ãƒ­ãƒ¼ã‚«ãƒ«ã®ã¿ã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Œäº†ï¼ˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆé€šä¿¡ãªã—ï¼‰")
    
    def test_sensitive_data_no_transmission(self):
        """æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã®éé€ä¿¡ç¢ºèª"""
        # å€‹äººæƒ…å ±ã®ä¾‹
        sensitive_texts = [
            "å€‹äººç•ªå·: 12345678",
            "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹: user@confidential.com",
            "é›»è©±ç•ªå·: 090-1234-5678"
        ]
        
        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
        embeddings = self.vectorizer.encode(sensitive_texts)
        
        # å‡¦ç†å®Œäº†ã‚’ç¢ºèª
        self.assertEqual(embeddings.shape[0], 3)
        self.assertTrue(np.all(np.isfinite(embeddings)))
        
        print("[OK] æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã®ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Œäº†")
    
    def test_vector_is_non_reversible(self):
        """ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰å…ƒãƒ†ã‚­ã‚¹ãƒˆã¯å¾©å·ä¸å¯èƒ½"""
        original_text = "æ©Ÿå¯†æƒ…å ±: password123"
        
        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
        embedding = self.vectorizer.encode(original_text)
        
        # ãƒ™ã‚¯ãƒˆãƒ«å½¢å¼ç¢ºèªï¼ˆä¸€æ–¹å‘å¤‰æ›ï¼‰
        self.assertEqual(len(embedding.shape), 2)
        self.assertEqual(embedding.shape[0], 1)
        
        # ãƒ™ã‚¯ãƒˆãƒ«ã¯æ•°å€¤é…åˆ—
        self.assertTrue(np.all(np.isfinite(embedding)))
        
        # Transformer ã¯ä¸€æ–¹å‘é–¢æ•° - é€†å¤‰æ›ä¸å¯èƒ½
        print("[OK] ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰å…ƒãƒ‡ãƒ¼ã‚¿ã¸ã®å¾©å·ä¸å¯èƒ½ã‚’ç¢ºèª")
    
    def test_model_offline_compliance(self):
        """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‹•ä½œç¢ºèªï¼‰"""
        info = self.vectorizer.get_model_info()
        
        # CPUå®Ÿè¡Œç¢ºèª
        self.assertIn('device', info)
        self.assertIn('model_name', info)
        self.assertIn('embedding_dimension', info)
        
        print(f"[OK] ãƒ¢ãƒ‡ãƒ«ç¢ºèª: {info['model_name']} (device: {info['device']})")



class TestTextVectorizerPerformance(unittest.TestCase):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
    
    @classmethod
    def setUpClass(cls):
        cls.vectorizer = TextVectorizer()
    
    def test_batch_processing_speed(self):
        """ãƒãƒƒãƒå‡¦ç†ã®é€Ÿåº¦"""
        texts = ["ãƒ†ã‚­ã‚¹ãƒˆ " + str(i) for i in range(100)]
        
        start_time = time.time()
        embeddings = self.vectorizer.encode_batch(texts, batch_size=32, show_progress=False)
        elapsed_time = time.time() - start_time
        
        # å‡¦ç†ãŒå®Œäº†ã—ãŸã“ã¨ã‚’ç¢ºèª
        self.assertEqual(embeddings.shape[0], 100)
        
        print(f"[PASS] ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆ (100æ–‡ in {elapsed_time:.2f}ç§’)")
    
    def test_large_batch_processing(self):
        """å¤§è¦æ¨¡ãƒãƒƒãƒå‡¦ç†"""
        texts = ["ãƒ†ã‚­ã‚¹ãƒˆ " + str(i) for i in range(500)]
        
        start_time = time.time()
        embeddings = self.vectorizer.encode_batch(texts, batch_size=64, show_progress=False)
        elapsed_time = time.time() - start_time
        
        self.assertEqual(embeddings.shape[0], 500)
        
        print(f"[PASS] å¤§è¦æ¨¡ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆ (500æ–‡ in {elapsed_time:.2f}ç§’)")


class TestTextVectorizerIntegration(unittest.TestCase):
    """çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    @classmethod
    def setUpClass(cls):
        cls.vectorizer = TextVectorizer()
    
    def test_complete_workflow(self):
        """å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
        # ãƒ†ã‚­ã‚¹ãƒˆé›†åˆ
        documents = [
            "Python ã¯å¼·åŠ›ãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™",
            "æ©Ÿæ¢°å­¦ç¿’ã¨æ·±å±¤å­¦ç¿’ã¯ AI ã®é‡è¦ãªåˆ†é‡ã§ã™",
            "Python ã¯æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå……å®Ÿã—ã¦ã„ã¾ã™",
            "Java ã¯ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºã«ä½¿ç”¨ã•ã‚Œã¾ã™",
            "Web é–‹ç™ºã«ã¯ JavaScript ã¨ Python ãŒä¸€èˆ¬çš„ã§ã™"
        ]
        
        # 1. ãƒ™ã‚¯ãƒˆãƒ«åŒ–
        embeddings = self.vectorizer.encode(documents)
        self.assertEqual(embeddings.shape[0], 5)
        
        # 2. é¡ä¼¼åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹
        similarity_matrix = self.vectorizer.similarity_matrix(documents)
        self.assertEqual(similarity_matrix.shape, (5, 5))
        
        # 3. ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢
        query = "Python ã¨æ©Ÿæ¢°å­¦ç¿’"
        results = self.vectorizer.find_similar_texts(query, documents, top_k=2)
        self.assertEqual(len(results), 2)
        
        # 4. DataFrameå¤‰æ›
        df = self.vectorizer.to_dataframe(documents, embeddings)
        self.assertEqual(len(df), 5)
        
        # 5. æ¬¡å…ƒå‰Šæ¸›ï¼ˆPCAï¼‰
        reduced = self.vectorizer.reduce_dimensions(embeddings, n_components=2, method="pca")
        self.assertEqual(reduced.shape, (5, 2))
        
        print("[PASS] çµ±åˆãƒ†ã‚¹ãƒˆ")


def run_tests():
    """ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    print("\n" + "=" * 70)
    print("TextVectorizer ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆé–‹å§‹")
    print("=" * 70)
    
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹ã‚’è¿½åŠ 
    suite.addTests(loader.loadTestsFromTestCase(TestTextVectorizerBasic))
    suite.addTests(loader.loadTestsFromTestCase(TestTextVectorizerSimilarity))
    suite.addTests(loader.loadTestsFromTestCase(TestTextVectorizerSearch))
    suite.addTests(loader.loadTestsFromTestCase(TestTextVectorizerDataFrame))
    suite.addTests(loader.loadTestsFromTestCase(TestTextVectorizerDimensionReduction))
    suite.addTests(loader.loadTestsFromTestCase(TestTextVectorizerModelInfo))
    suite.addTests(loader.loadTestsFromTestCase(TestTextVectorizerErrorHandling))
    suite.addTests(loader.loadTestsFromTestCase(TestTextVectorizerSecurity))  # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆè¿½åŠ 
    suite.addTests(loader.loadTestsFromTestCase(TestTextVectorizerPerformance))
    suite.addTests(loader.loadTestsFromTestCase(TestTextVectorizerIntegration))
    
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "=" * 70)
    print(f"ãƒ†ã‚¹ãƒˆå®Œäº†: {result.testsRun}ä»¶å®Ÿè¡Œ")
    print(f"[OK] æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"[NG] å¤±æ•—: {len(result.failures)}")
    print(f"[NG] ã‚¨ãƒ©ãƒ¼: {len(result.errors)}")
    print("=" * 70 + "\n")
    
    return result.wasSuccessful()


if __name__ == '__main__':
    success = run_tests()
    sys.exit(0 if success else 1)
